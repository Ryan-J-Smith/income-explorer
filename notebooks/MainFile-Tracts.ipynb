{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main File - Tract Level\n",
    "\n",
    "This file is used for getting and acquiring census data at the tract level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from census import Census\n",
    "from us import states\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Specify state and county to download (select one)\n",
    "loc_name, state_codes, county_codes = \"maryland\", states.MD.fips, None\n",
    "loc_name, state_codes, county_codes = \"delmarva\", [states.MD.fips, states.DE.fips, states.VA.fips], None\n",
    "\n",
    "if county_codes is not None:\n",
    "    county_list = [\"{:03d}\".format(county_id) for county_id in county_codes]\n",
    "else:\n",
    "    county_list = None\n",
    "\n",
    "# CENSUS API Stuff\n",
    "CENSUS_API = #YourAPIKeyHere\n",
    "c = Census(CENSUS_API) # Initialize census class with API key\n",
    "\n",
    "# Generate codes for census variables of interest\n",
    "var_ids = [\"B19001_0{:02d}E\".format(x) for x in range(2, 18)] # Household income over 12 months\n",
    "\n",
    "# TIGER Stuff\n",
    "TIGER_BASE_URL = 'http://www2.census.gov/geo/tiger/TIGER2013/'\n",
    "TIGER_TRACT_DIR = 'TRACT/'\n",
    "TIGER_BLOCKGROUP_DIR = 'BG/'\n",
    "\n",
    "TIGER_WATER_DIR = 'AREAWATER/'\n",
    "\n",
    "tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_code)\n",
    "tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_code)\n",
    "\n",
    "FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "\n",
    "# Local Storage Parameters\n",
    "LOCAL_DATA_DIR = './data/'\n",
    "GEO_SUB_DIR = 'geo/'\n",
    "\n",
    "ATTR_FILE_END = '_census_data.csv'\n",
    "attr_outfile = LOCAL_DATA_DIR + loc_name + ATTR_FILE_END\n",
    "\n",
    "GEO_FILE_END = '_geo_data.json'\n",
    "geo_outfile = LOCAL_DATA_DIR + loc_name + GEO_FILE_END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_data = c.acs.get(var_ids, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "census_df = pd.DataFrame(census_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_002E</th>\n",
       "      <th>B19001_003E</th>\n",
       "      <th>B19001_004E</th>\n",
       "      <th>B19001_005E</th>\n",
       "      <th>B19001_006E</th>\n",
       "      <th>B19001_007E</th>\n",
       "      <th>B19001_008E</th>\n",
       "      <th>B19001_009E</th>\n",
       "      <th>B19001_010E</th>\n",
       "      <th>B19001_011E</th>\n",
       "      <th>B19001_012E</th>\n",
       "      <th>B19001_013E</th>\n",
       "      <th>B19001_014E</th>\n",
       "      <th>B19001_015E</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>202</td>\n",
       "      <td>136</td>\n",
       "      <td>159</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>127</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>73</td>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>119</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>167</td>\n",
       "      <td>37</td>\n",
       "      <td>103</td>\n",
       "      <td>51</td>\n",
       "      <td>213</td>\n",
       "      <td>72</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>76</td>\n",
       "      <td>109</td>\n",
       "      <td>118</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "      <td>108</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>157</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>157</td>\n",
       "      <td>75</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19001_002E B19001_003E B19001_004E B19001_005E B19001_006E B19001_007E  \\\n",
       "0         101          97          81         105          76         126   \n",
       "1          94          80         127          36          60          58   \n",
       "2          86         167          37         103          51         213   \n",
       "3          87          77          95          53         108          89   \n",
       "4         298         157          75          41          63          48   \n",
       "\n",
       "  B19001_008E B19001_009E B19001_010E B19001_011E B19001_012E B19001_013E  \\\n",
       "0          67          51          80         202         136         159   \n",
       "1          37          73          44         122          95         138   \n",
       "2          72          38          12          76         109         118   \n",
       "3          89          55          87          90          80          95   \n",
       "4          42           6          43          93          40          35   \n",
       "\n",
       "  B19001_014E B19001_015E B19001_016E B19001_017E county state   tract  \n",
       "0         113          18           8           0    001    24  000100  \n",
       "1         119          32          40          17    001    24  000200  \n",
       "2          39          22          10           7    001    24  000300  \n",
       "3         157          64          14          18    001    24  000400  \n",
       "4          37          36           8           0    001    24  000500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get census (attribute) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bg_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract'] + record['block group']\n",
    "    return str(fips_code)\n",
    "\n",
    "def build_tract_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract']\n",
    "    return str(fips_code)\n",
    "\n",
    "\n",
    "def census_bg_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def census_tracts_to_dataframe(var_list, state_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for state_id in state_codes:\n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "\n",
    "        for idx, record in enumerate(census_data):\n",
    "\n",
    "            # Build fips codes\n",
    "            fips_code = build_tract_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "      \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This segment of code will get household income estimates for each block group in Baltimore city\n",
    "census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "census_df.to_csv(attr_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TIGER (shape) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already had the file.  Great.\n",
      "Got the file! Copying to disk.\n",
      "Got the file! Copying to disk.\n"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_id)\n",
    "\n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "\n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print(\"Already had the file.  Great.\")\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim shape data to match attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_shapes = []\n",
    "for idx, state_id in enumerate(state_codes):\n",
    "    tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_id)\n",
    "    tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_id)\n",
    "\n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "\n",
    "    # Load to GeoDataFrame\n",
    "    state_shape = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "    \n",
    "    state_shapes.append(state_shape)\n",
    "    \n",
    "    # Only keep counties that we are interested in\n",
    "    if county_list is not None:\n",
    "        shapes = shapes[shapes[\"COUNTYFP\"].isin(county_list)]\n",
    "\n",
    "shapes = gpd.GeoDataFrame( pd.concat(state_shapes, ignore_index=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate unneeded attributes, export shapes to geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\")\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
